{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "#from jupyterthemes import jtplot\n",
    "\n",
    "import nmca_model\n",
    "from TwoChannelModel import TwoChannelModel\n",
    "from correlation_analysis import CCA, PCC_Matrix\n",
    "from plot import plot_eval\n",
    "from tf_summary import write_scalar_summary, write_image_summary, write_PCC_summary\n",
    "\n",
    "LOGPATH = '/var/tmp/mkuschel/tf_logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = TwoChannelModel(num_samples=1000)\n",
    "y_1, y_2, Az_1, Az_2, z_1, z_2 = data_model('Parabola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwoChannelModel.plot_shared_components(z_1, z_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwoChannelModel.plot_non_linearities(y_1, y_2, Az_1, Az_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nmca_model.build_nmca_model(hdim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train one network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#writer, folder = nmca_model.create_writer(LOGPATH)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "lambda_reg = 1e-10\n",
    "shared_dim = 0\n",
    "sum_of_grads = list()\n",
    "t_ccor = [1,1,0,0,0]\n",
    "\n",
    "for epoch in tqdm(range(100000), desc='Epochs'):\n",
    "    if epoch%20000 == 0:\n",
    "            if shared_dim < 4:\n",
    "                shared_dim += 1\n",
    "                print(str(shared_dim)+\" shared dimensions\")\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Watch the input to be able to compute the gradient later\n",
    "        tape.watch([y_1, y_2])\n",
    "        # Forward path\n",
    "        [fy_1, fy_2], [yhat_1, yhat_2] = model([tf.transpose(y_1), tf.transpose(y_2)])\n",
    "        # Loss computation\n",
    "        loss, cca_loss, rec_loss, ccor = nmca_model.compute_loss(y_1, y_2, fy_1, fy_2, yhat_1, yhat_2, shared_dim, lambda_reg=lambda_reg)\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        sum_of_grads.append(np.sum([np.linalg.norm(grad) for grad in gradients]))\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            B1, B2, epsilon, omega, ccor = CCA(fy_1, fy_2, 5)\n",
    "            if t_ccor[0] == 1:\n",
    "                sim_v1 = nmca_model.compute_similarity_metric_v1(S=z_1[:2], U=0.5*(omega+epsilon))\n",
    "            else:\n",
    "                sim_v1 = 0\n",
    "            sim_v2 = nmca_model.compute_similarity_metric_v1(S=z_1[:2], U=epsilon)\n",
    "            sim_v3 = nmca_model.compute_similarity_metric_v1(S=z_2[:2], U=omega)\n",
    "            dist = nmca_model.compute_distance_metric(S=z_1[:2], U=0.5 * (omega + epsilon)[:2])\n",
    "\n",
    "            write_scalar_summary(\n",
    "                writer=writer, \n",
    "                epoch=epoch, \n",
    "                list_of_tuples=[\n",
    "                    (np.sum(sum_of_grads), 'Gradients/Sum'),\n",
    "                    (loss, 'Loss/Total'),\n",
    "                    (cca_loss, 'Loss/CCA'),\n",
    "                    (rec_loss, 'Loss/reconstruction'),\n",
    "                    (ccor[0], 'Canonical correlation/0'),\n",
    "                    (ccor[1], 'Canonical correlation/1'),\n",
    "                    (ccor[2], 'Canonical correlation/2'),\n",
    "                    (ccor[3], 'Canonical correlation/3'),\n",
    "                    (ccor[4], 'Canonical correlation/4'),\n",
    "                    (dist, 'Performance Measures/Distance measure'),\n",
    "                    (sim_v1, 'Performance Measures/Similarity measure'),\n",
    "                    (sim_v2, 'Performance Measures/Similarity measure 1st view'),\n",
    "                    (sim_v3, 'Performance Measures/Similarity measure 2nd view'),\n",
    "                ]\n",
    "            )\n",
    "            sum_of_grads = list()\n",
    "\n",
    "        if epoch % 5000 == 0:\n",
    "            write_image_summary(writer, epoch, Az_1, Az_2, y_1, y_2, fy_1, fy_2, yhat_1, yhat_2)\n",
    "            write_PCC_summary(writer, epoch, z_1, z_2, epsilon, omega, 1000)\n",
    "            \n",
    "    \n",
    "    # Backpropagate through network\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "model.save(log_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward path\n",
    "[fy_1, fy_2], [yhat_1, yhat_2] = model([tf.transpose(y_1), tf.transpose(y_2)])\n",
    "\n",
    "# Compute CCA\n",
    "B1, B2, epsilon, omega, ccor = CCA(fy_1, fy_2, 2)\n",
    "\n",
    "fy_1, fy_2 = tf.transpose(fy_1), tf.transpose(fy_2)\n",
    "yhat_1, yhat_2 = tf.transpose(yhat_1), tf.transpose(yhat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = z_1[:2]\n",
    "Ps = np.eye(1000) - tf.transpose(S)@np.linalg.inv(S@tf.transpose(S))@S\n",
    "U = 0.5*(omega+epsilon)\n",
    "Q = scipy.linalg.orth(tf.transpose(U))\n",
    "dist = np.linalg.norm(Ps@Q, ord=2)\n",
    "print(\"Dist: \"+str(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_eval(z_1, z_2, Az_1, Az_2, y_1, y_2, fy_1, fy_2, yhat_1, yhat_2, epsilon, omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
